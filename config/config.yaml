# Конфигурация эксперимента VKR_Patch
# Применение PatchTST для портфельной оптимизации Марковица

# Параметры данных
data:
  tickers:                          # 10 акций из разных секторов S&P 500
    - AAPL   # Technology
    - MSFT   # Technology
    - JNJ    # Healthcare
    - UNH    # Healthcare
    - JPM    # Financials
    - WFC    # Financials (Wells Fargo)
    - XOM    # Energy
    - CVX    # Energy
    - PG     # Consumer Staples
    - KO     # Consumer Staples
  start_date: "2010-01-01"
  end_date: "2025-01-01"
  price_column: "Adj Close"         # Используем скорректированные цены

# Параметры бэктестинга
backtest:
  train_window: 1260                # 5 лет * 252 торговых дня
  test_window: 21                   # 1 месяц (21 торговый день)

# Параметры моделей
models:
  # ARIMA(p, d, q) с автоматическим подбором (StatsForecast AutoARIMA):
  #   p — порядок авторегрессии (AR), зависимость от прошлых значений
  #   d — порядок дифференцирования (I), для приведения к стационарности
  #   q — порядок скользящего среднего (MA), зависимость от прошлых ошибок
  #   stepwise=True — умный поиск вместо полного перебора (быстрее в ~10 раз)
  arima:
    max_p: 3                        # AR: r_t зависит от r_{t-1}, ..., r_{t-p}
    max_d: 1                        # Максимальный порядок дифференцирования
    max_q: 3                        # MA: r_t зависит от ε_{t-1}, ..., ε_{t-q}
    stepwise: true                  # Умный поиск (не полный перебор)

  patchtst:
    # Режим: 'fast' для отладки, 'full' для финальных результатов
    mode: "full"

    # Режим отладки (~10 минут, проверка что код работает)
    # Уменьшенные параметры для быстрой проверки работоспособности кода
    fast:
      input_length: 252             # 1 год (даёт 988 примеров для fine-tuning)
      pred_length: 21               # Как в full
      patch_length: 21              # Больше → меньше патчей
      stride: 21                    # Без перекрытия → 12 патчей
      d_model: 64                   # Уменьшено 128→64 для скорости
      n_heads: 4                    # Уменьшено 16→4 для скорости
      n_layers: 2                   # Уменьшено 3→2 для скорости
      d_ff: 256                     # Уменьшено 512→256 для скорости
      dropout: 0.2                  # Как в full (официальное)
      use_revin: true               # Как в full
      mask_ratio: 0.4               # Как в full (официальное)
      pretrain_epochs: 3            # Уменьшено 10→3 для скорости
      finetune_epochs: 3            # Fine-tuning prediction head
      pretrain_lr: 0.0001           # Как в full (официальное)
      batch_size: 64                # Как в full (официальное)

    # Полный режим (официальные параметры Self-Supervised PatchTST)
    # Источник: github.com/yuqinie98/PatchTST/PatchTST_self_supervised/patchtst_pretrain.py
    # Официальные дефолты из argument parser:
    #   --d_model 128, --n_heads 16, --n_layers 3, --d_ff 512
    #   --dropout 0.2, --mask_ratio 0.4, --lr 1e-4
    #   --batch_size 64, --n_epochs_pretrain 10
    #
    # input_length=252 (1 год) даёт:
    #   - 988 примеров для fine-tuning (1260-252-21+1)
    #   - 202 примеров для pretraining ((1260-252)/5+1)
    #   - 30 патчей ((252-16)/8+1)
    full:
      input_length: 252             # 1 год (официальный подход: input << train_window)
      pred_length: 21               # 1 месяц
      patch_length: 16              # Официальное
      stride: 8                     # Официальное (с перекрытием)
      d_model: 128                  # Официальное
      n_heads: 16                   # Официальное
      n_layers: 3                   # Официальное
      d_ff: 512                     # Официальное (patchtst_pretrain.py)
      dropout: 0.15                  # Официальное
      use_revin: true               # Рекомендовано в PatchTST
      mask_ratio: 0.15               # Официальное
      pretrain_epochs: 20           # Официальное (self-supervised)
      finetune_epochs: 10            # Fine-tuning prediction head (supervised)
      pretrain_lr: 0.005           # Официальное (1e-4)
      batch_size: 64                # Официальное

# Параметры оптимизации Марковица
optimization:
  risk_free_rate: 0.04              # Безрисковая ставка (2% годовых)
  covariance: "ledoit_wolf"              # sample | ledoit_wolf

  constraints:
    long_only: true                 # Только длинные позиции (w >= 0)
    fully_invested: true            # Полное инвестирование (sum(w) = 1)
    max_weight: 0.25                # Максимальный вес одного актива (40%)
    min_weight: 0.05                # Минимальный вес
    gross_exposure: 1.5             # sum(|w|) <= L (используется только при long_only=false)
