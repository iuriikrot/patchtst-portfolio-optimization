{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d3f52f",
   "metadata": {},
   "source": [
    "# Сравнение подходов к оценке ожидаемой доходности в портфельной оптимизации Марковица\n",
    "\n",
    "**Три подхода:**\n",
    "1. Baseline 1: Историческое среднее\n",
    "2. Baseline 2: StatsForecast AutoARIMA прогноз\n",
    "3. PatchTST Self-Supervised прогноз\n",
    "\n",
    "**Источник PatchTST:** https://github.com/yuqinie98/PatchTST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e69e1",
   "metadata": {},
   "source": [
    "## 0. Конфигурация\n",
    "Все параметры эксперимента в одном месте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a3653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# КОНФИГУРАЦИЯ ЭКСПЕРИМЕНТА\n",
    "# Измените параметры здесь перед запуском\n",
    "#==============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Данные\n",
    "    'data': {\n",
    "        'tickers': [\n",
    "            \"AAPL\",  # Technology\n",
    "            \"MSFT\",  # Technology\n",
    "            \"JNJ\",   # Healthcare\n",
    "            \"UNH\",   # Healthcare\n",
    "            \"JPM\",   # Financials\n",
    "            \"WFC\",   # Financials (Wells Fargo)\n",
    "            \"XOM\",   # Energy\n",
    "            \"CVX\",   # Energy\n",
    "            \"PG\",    # Consumer Staples\n",
    "            \"KO\",    # Consumer Staples\n",
    "        ],\n",
    "        'start_date': \"2000-01-01\",\n",
    "        'end_date': \"2025-01-01\",\n",
    "    },\n",
    "\n",
    "    # Параметры бэктеста\n",
    "    'backtest': {\n",
    "        'train_window': 1260,  # 5 лет (252 * 5)\n",
    "        'test_window': 21,     # 1 месяц\n",
    "    },\n",
    "\n",
    "    # Оптимизация Марковица\n",
    "    'optimization': {\n",
    "        'risk_free_rate': 0.02,  # 2% годовых\n",
    "        'constraints': {\n",
    "            'long_only': True,      # Только длинные позиции\n",
    "            'fully_invested': True, # Полное инвестирование\n",
    "            'max_weight': 0.4,      # Максимальный вес одного актива\n",
    "            'min_weight': 0.0,      # Минимальный вес\n",
    "            'gross_exposure': 1.5,  # sum(|w|) <= L (используется только при long_only=false)\n",
    "        },\n",
    "        'covariance': 'sample',    # sample | ledoit_wolf\n",
    "    },\n",
    "\n",
    "    # Модели\n",
    "    'models': {\n",
    "        # ARIMA(p, d, q) с автоматическим подбором (StatsForecast AutoARIMA):\n",
    "        #   p — порядок авторегрессии (AR), зависимость от прошлых значений\n",
    "        #   d — порядок дифференцирования (I), для приведения к стационарности\n",
    "        #   q — порядок скользящего среднего (MA), зависимость от прошлых ошибок\n",
    "        # max_d: верхняя граница для d\n",
    "        # stepwise=True: умный поиск вместо полного перебора (~10x быстрее)\n",
    "        'arima': {\n",
    "            'max_p': 3,  # AR: r_t зависит от r_{t-1}, r_{t-2}, r_{t-3}\n",
    "            'max_d': 0,  # Максимальный порядок дифференцирования\n",
    "            'max_q': 3,  # MA: r_t зависит от ε_{t-1}, ε_{t-2}, ε_{t-3}\n",
    "            'stepwise': True,  # Умный поиск (не полный перебор)\n",
    "        },\n",
    "\n",
    "        # PatchTST Self-Supervised\n",
    "        'patchtst': {\n",
    "            # Режим: 'fast' для отладки, 'full' для финальных результатов\n",
    "            'mode': 'full',\n",
    "\n",
    "            # Режим отладки (~10 минут, проверка что код работает)\n",
    "            'fast': {\n",
    "                'input_length': 252,     # 1 год (даёт 988 примеров для fine-tuning)\n",
    "                'pred_length': 21,\n",
    "                'patch_length': 21,      # Больше → меньше патчей\n",
    "                'stride': 21,            # Без перекрытия → 12 патчей\n",
    "                'd_model': 64,           # Уменьшено для скорости\n",
    "                'n_heads': 4,            # Уменьшено для скорости\n",
    "                'n_layers': 2,           # Уменьшено для скорости\n",
    "                'd_ff': 256,             # Уменьшено для скорости\n",
    "                'dropout': 0.2,\n",
    "                'use_revin': True,\n",
    "                'mask_ratio': 0.4,\n",
    "                'pretrain_epochs': 3,    # Минимум для проверки\n",
    "                'finetune_epochs': 3,    # Fine-tuning prediction head\n",
    "                'pretrain_lr': 0.0001,\n",
    "                'batch_size': 64,\n",
    "            },\n",
    "\n",
    "            # Полный режим (официальные параметры Self-Supervised PatchTST)\n",
    "            # Источник: github.com/yuqinie98/PatchTST/PatchTST_self_supervised/patchtst_pretrain.py\n",
    "            # input_length=252 (1 год) даёт: 988 примеров, 30 патчей\n",
    "            'full': {\n",
    "                'input_length': 252,     # 1 год (официальный подход: input << train_window)\n",
    "                'pred_length': 21,\n",
    "                'patch_length': 16,      # Официальное\n",
    "                'stride': 8,             # Официальное → 30 патчей\n",
    "                'd_model': 128,          # Официальное\n",
    "                'n_heads': 16,           # Официальное\n",
    "                'n_layers': 3,           # Официальное\n",
    "                'd_ff': 512,             # Официальное\n",
    "                'dropout': 0.2,          # Официальное\n",
    "                'use_revin': True,\n",
    "                'mask_ratio': 0.4,       # Официальное\n",
    "                'pretrain_epochs': 10,   # Официальное (self-supervised)\n",
    "                'finetune_epochs': 5,    # Fine-tuning prediction head\n",
    "                'pretrain_lr': 0.0001,   # Официальное (1e-4)\n",
    "                'batch_size': 64,        # Официальное\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Извлекаем параметры для удобства\n",
    "TICKERS = CONFIG['data']['tickers']\n",
    "START_DATE = CONFIG['data']['start_date']\n",
    "END_DATE = CONFIG['data']['end_date']\n",
    "\n",
    "TRAIN_WINDOW = CONFIG['backtest']['train_window']\n",
    "TEST_WINDOW = CONFIG['backtest']['test_window']\n",
    "RF = CONFIG['optimization']['risk_free_rate']\n",
    "CONSTRAINTS = CONFIG['optimization'].get('constraints', {})\n",
    "MIN_WEIGHT = CONSTRAINTS.get('min_weight', 0.0)\n",
    "MAX_WEIGHT = CONSTRAINTS.get('max_weight', 1.0)\n",
    "LONG_ONLY = CONSTRAINTS.get('long_only', True)\n",
    "FULLY_INVESTED = CONSTRAINTS.get('fully_invested', True)\n",
    "COV_METHOD = CONFIG['optimization'].get('covariance', 'sample')\n",
    "GROSS_EXPOSURE = CONSTRAINTS.get('gross_exposure')\n",
    "\n",
    "# ARIMA\n",
    "ARIMA_MAX_P = CONFIG['models']['arima']['max_p']\n",
    "ARIMA_MAX_D = CONFIG['models']['arima']['max_d']\n",
    "ARIMA_MAX_Q = CONFIG['models']['arima']['max_q']\n",
    "ARIMA_STEPWISE = CONFIG['models']['arima']['stepwise']\n",
    "\n",
    "# PatchTST - выбираем режим\n",
    "PATCHTST_MODE = CONFIG['models']['patchtst']['mode']\n",
    "patchtst_config = CONFIG['models']['patchtst'][PATCHTST_MODE]\n",
    "\n",
    "INPUT_LEN = patchtst_config['input_length']\n",
    "PRED_LEN = patchtst_config['pred_length']\n",
    "PATCH_LEN = patchtst_config['patch_length']\n",
    "STRIDE = patchtst_config['stride']\n",
    "D_MODEL = patchtst_config['d_model']\n",
    "N_HEADS = patchtst_config['n_heads']\n",
    "N_LAYERS = patchtst_config['n_layers']\n",
    "D_FF = patchtst_config['d_ff']\n",
    "DROPOUT = patchtst_config['dropout']\n",
    "USE_REVIN = patchtst_config['use_revin']\n",
    "MASK_RATIO = patchtst_config['mask_ratio']\n",
    "PRETRAIN_EPOCHS = patchtst_config['pretrain_epochs']\n",
    "FINETUNE_EPOCHS = patchtst_config['finetune_epochs']\n",
    "PRETRAIN_LR = patchtst_config['pretrain_lr']\n",
    "BATCH_SIZE = patchtst_config['batch_size']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"КОНФИГУРАЦИЯ ЭКСПЕРИМЕНТА\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Данные: {len(TICKERS)} акций, {START_DATE} — {END_DATE}\")\n",
    "print(f\"Бэктест: train={TRAIN_WINDOW} дней, test={TEST_WINDOW} дней\")\n",
    "print(f\"PatchTST режим: {PATCHTST_MODE.upper()}\")\n",
    "print(f\"  - патчей: {(INPUT_LEN - PATCH_LEN) // STRIDE + 1}\")\n",
    "print(f\"  - d_model={D_MODEL}, n_heads={N_HEADS}, n_layers={N_LAYERS}\")\n",
    "print(f\"  - pretrain_epochs={PRETRAIN_EPOCHS}, finetune_epochs={FINETUNE_EPOCHS}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df55b05b",
   "metadata": {},
   "source": [
    "## 1. Установка и импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b75e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance statsforecast torch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройки отображения\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Проверка GPU (MPS -> CUDA -> CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f\"PyTorch device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b092ed",
   "metadata": {},
   "source": [
    "## 2. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff8aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Скачивание данных с Yahoo Finance...\")\n",
    "data = yf.download(\n",
    "    tickers=TICKERS,\n",
    "    start=START_DATE,\n",
    "    end=END_DATE,\n",
    "    auto_adjust=False\n",
    ")\n",
    "\n",
    "prices = data[\"Adj Close\"]\n",
    "prices = prices.dropna()\n",
    "\n",
    "log_returns = np.log(prices / prices.shift(1))\n",
    "log_returns = log_returns.dropna()\n",
    "\n",
    "print(f\"Загружено {len(prices)} торговых дней\")\n",
    "print(f\"Период: {prices.index[0].date()} — {prices.index[-1].date()}\")\n",
    "print(f\"Рассчитано {len(log_returns)} дневных доходностей\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2e57f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Визуализация\n",
    "normalized_prices = prices / prices.iloc[0] * 100\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for ticker in TICKERS:\n",
    "    plt.plot(normalized_prices[ticker], label=ticker, alpha=0.8)\n",
    "\n",
    "plt.title(\"Динамика цен акций (нормализовано к 100)\")\n",
    "plt.xlabel(\"Дата\")\n",
    "plt.ylabel(\"Цена (нормализованная)\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1fc9d3",
   "metadata": {},
   "source": [
    "## 3. Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01bb7a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def maximize_sharpe(\n",
    "    mu,\n",
    "    cov,\n",
    "    rf=0.02,\n",
    "    min_weight=0.0,\n",
    "    max_weight=1.0,\n",
    "    long_only=True,\n",
    "    fully_invested=True\n",
    "):\n",
    "    \"\"\"Максимизация коэффициента Шарпа.\"\"\"\n",
    "    n = len(mu)\n",
    "    w0 = np.ones(n) / n\n",
    "\n",
    "    def neg_sharpe(w):\n",
    "        port_return = np.dot(w, mu)\n",
    "        port_vol = np.sqrt(np.dot(w, np.dot(cov, w)))\n",
    "        if port_vol < 1e-10:\n",
    "            return 1e10  # Избегаем деления на ноль\n",
    "        return -(port_return - rf) / port_vol\n",
    "\n",
    "    if long_only and min_weight < 0:\n",
    "        min_weight = 0.0\n",
    "\n",
    "    constraints = []\n",
    "    if fully_invested:\n",
    "        constraints.append({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(min_weight, max_weight) for _ in range(n)]\n",
    "\n",
    "    result = minimize(neg_sharpe, w0, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result.x\n",
    "\n",
    "\n",
    "def calculate_metrics(returns, rf=0.02):\n",
    "    \"\"\"Расчёт метрик портфеля (returns — месячные лог-доходности).\"\"\"\n",
    "    simple_returns = np.exp(returns) - 1\n",
    "    monthly_rf = (1 + rf) ** (1 / 12) - 1\n",
    "    excess = simple_returns - monthly_rf\n",
    "\n",
    "    if len(simple_returns) > 0:\n",
    "        annual_return = (1 + simple_returns).prod() ** (12 / len(simple_returns)) - 1\n",
    "    else:\n",
    "        annual_return = 0\n",
    "    annual_vol = simple_returns.std() * np.sqrt(12)\n",
    "    sharpe = (excess.mean() / simple_returns.std() * np.sqrt(12)) if simple_returns.std() > 0 else 0\n",
    "\n",
    "    cumulative = (1 + simple_returns).cumprod()\n",
    "    rolling_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - rolling_max) / rolling_max\n",
    "    max_drawdown = drawdown.min()\n",
    "\n",
    "    total_return = (1 + simple_returns).prod() - 1\n",
    "\n",
    "    # Calmar Ratio = Annual Return / |Max Drawdown|\n",
    "    calmar = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "\n",
    "    return {\n",
    "        'Annual Return': annual_return,\n",
    "        'Annual Volatility': annual_vol,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        'Calmar Ratio': calmar,\n",
    "        'Max Drawdown': max_drawdown,\n",
    "        'Total Return': total_return,\n",
    "        'Num Periods': len(returns)\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_monthly_log_return(test_data, weights, fully_invested=True):\n",
    "    \"\"\"Доходность за месяц при ребалансировке раз в месяц (buy-and-hold).\"\"\"\n",
    "    asset_gross = np.exp(test_data.sum(axis=0).values)\n",
    "    portfolio_gross = np.dot(weights, asset_gross)\n",
    "    if not fully_invested:\n",
    "        portfolio_gross += (1 - weights.sum())\n",
    "    return np.log(portfolio_gross)\n",
    "\n",
    "\n",
    "def compute_covariance(returns, method=\"sample\", annualize=252):\n",
    "    \"\"\"Оценка ковариации.\"\"\"\n",
    "    if method == \"sample\":\n",
    "        cov = returns.cov().values\n",
    "    elif method == \"ledoit_wolf\":\n",
    "        lw = LedoitWolf().fit(returns.values)\n",
    "        cov = lw.covariance_\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестный метод ковариации: {method}\")\n",
    "    return cov * annualize\n",
    "\n",
    "\n",
    "def calculate_forecast_metrics(actual, predicted):\n",
    "    \"\"\"\n",
    "    Рассчитать метрики качества прогноза.\n",
    "\n",
    "    Args:\n",
    "        actual: array — фактические месячные доходности по тикерам\n",
    "        predicted: array — прогнозные месячные доходности по тикерам\n",
    "\n",
    "    Returns:\n",
    "        dict с метриками: RMSE, MAE, Hit Rate\n",
    "    \"\"\"\n",
    "    # Убираем NaN\n",
    "    mask = ~(np.isnan(actual) | np.isnan(predicted))\n",
    "    actual = actual[mask]\n",
    "    predicted = predicted[mask]\n",
    "\n",
    "    if len(actual) == 0:\n",
    "        return {'rmse': np.nan, 'mae': np.nan, 'hit_rate': np.nan}\n",
    "\n",
    "    # RMSE\n",
    "    rmse = np.sqrt(np.mean((actual - predicted) ** 2))\n",
    "\n",
    "    # MAE\n",
    "    mae = np.mean(np.abs(actual - predicted))\n",
    "\n",
    "    # Hit Rate (совпадение знаков)\n",
    "    nonzero_mask = (actual != 0) & (predicted != 0)\n",
    "    if nonzero_mask.sum() > 0:\n",
    "        hits = np.sign(actual[nonzero_mask]) == np.sign(predicted[nonzero_mask])\n",
    "        hit_rate = hits.mean()\n",
    "    else:\n",
    "        hit_rate = np.nan\n",
    "\n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'hit_rate': hit_rate\n",
    "    }\n",
    "\n",
    "\n",
    "def aggregate_forecast_metrics(forecasts_df):\n",
    "    \"\"\"\n",
    "    Агрегировать метрики по всем периодам бэктеста.\n",
    "\n",
    "    Args:\n",
    "        forecasts_df: DataFrame с колонками:\n",
    "            - date: дата ребалансировки\n",
    "            - ticker: тикер\n",
    "            - actual: фактическая месячная доходность\n",
    "            - predicted: прогнозная месячная доходность\n",
    "\n",
    "    Returns:\n",
    "        dict с агрегированными метриками\n",
    "    \"\"\"\n",
    "    actual = forecasts_df['actual'].values\n",
    "    predicted = forecasts_df['predicted'].values\n",
    "\n",
    "    return calculate_forecast_metrics(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad8811",
   "metadata": {},
   "source": [
    "## 4. Baseline 1: Историческое среднее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa727b6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_backtest_baseline1(returns, train_window, test_window, rf, collect_forecasts=True, collect_weights=False):\n",
    "    \"\"\"Бэктест: μ = историческое среднее.\"\"\"\n",
    "    n = len(returns)\n",
    "    portfolio_returns = []\n",
    "    dates = []\n",
    "    forecast_records = [] if collect_forecasts else None\n",
    "    weights_list = [] if collect_weights else None\n",
    "\n",
    "    total_steps = (n - train_window - test_window) // test_window + 1\n",
    "    i = 0\n",
    "    step = 0\n",
    "\n",
    "    while i + train_window + test_window <= n:\n",
    "        train_data = returns.iloc[i:i + train_window]\n",
    "        test_data = returns.iloc[i + train_window:i + train_window + test_window]\n",
    "\n",
    "        daily_mean = train_data.mean()\n",
    "        mu = daily_mean.values * 252\n",
    "        cov = compute_covariance(train_data, method=COV_METHOD, annualize=252)\n",
    "\n",
    "        # Собираем прогнозы если нужно\n",
    "        if collect_forecasts:\n",
    "            # Для Baseline 1: прогноз = историческое среднее на каждый день\n",
    "            raw_forecasts = pd.DataFrame(\n",
    "                np.tile(daily_mean.values, (test_window, 1)),\n",
    "                columns=returns.columns\n",
    "            )\n",
    "            # Actual = сумма дневных доходностей за месяц\n",
    "            actual_monthly = test_data.sum(axis=0)\n",
    "            # Predicted = сумма прогнозов за месяц\n",
    "            predicted_monthly = raw_forecasts.sum(axis=0)\n",
    "            # Собираем записи для каждого тикера\n",
    "            for ticker in returns.columns:\n",
    "                forecast_records.append({\n",
    "                    'date': test_data.index[0],\n",
    "                    'ticker': ticker,\n",
    "                    'actual': actual_monthly[ticker],\n",
    "                    'predicted': predicted_monthly[ticker],\n",
    "                    'model': 'Historical'\n",
    "                })\n",
    "\n",
    "        weights = maximize_sharpe(\n",
    "            mu,\n",
    "            cov,\n",
    "            rf=rf,\n",
    "            min_weight=MIN_WEIGHT,\n",
    "            max_weight=MAX_WEIGHT,\n",
    "            long_only=LONG_ONLY,\n",
    "            fully_invested=FULLY_INVESTED,\n",
    "            gross_exposure=GROSS_EXPOSURE\n",
    "        )\n",
    "\n",
    "        month_return = compute_monthly_log_return(\n",
    "            test_data,\n",
    "            weights,\n",
    "            fully_invested=FULLY_INVESTED\n",
    "        )\n",
    "\n",
    "        portfolio_returns.append(month_return)\n",
    "        dates.append(test_data.index[0])\n",
    "        if weights_list is not None:\n",
    "            weights_list.append(weights)\n",
    "\n",
    "        step += 1\n",
    "        i += test_window\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            print(f\"  Шаг {step}/{total_steps} ({step*100//total_steps}%)\")\n",
    "\n",
    "    print(f\"  Завершено: {step} периодов\")\n",
    "    result = pd.Series(portfolio_returns, index=dates)\n",
    "\n",
    "    # Возврат результатов\n",
    "    returns_tuple = [result]\n",
    "    if collect_forecasts:\n",
    "        forecasts_df = pd.DataFrame(forecast_records)\n",
    "        returns_tuple.append(forecasts_df)\n",
    "    if collect_weights:\n",
    "        weights_df = pd.DataFrame(weights_list, index=dates, columns=returns.columns)\n",
    "        returns_tuple.append(weights_df)\n",
    "\n",
    "    return tuple(returns_tuple) if len(returns_tuple) > 1 else result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f812339",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"Baseline 1: Историческое среднее\")\n",
    "print(\"=\"*50)\n",
    "baseline1_returns, baseline1_forecasts, baseline1_weights = run_backtest_baseline1(\n",
    "    log_returns, TRAIN_WINDOW, TEST_WINDOW, RF, collect_forecasts=True, collect_weights=True\n",
    ")\n",
    "baseline1_metrics = calculate_metrics(baseline1_returns, rf=RF)\n",
    "baseline1_forecast_metrics = aggregate_forecast_metrics(baseline1_forecasts)\n",
    "\n",
    "print(\"\\nРезультаты (Портфель):\")\n",
    "for name, value in baseline1_metrics.items():\n",
    "    if 'Return' in name or 'Volatility' in name or 'Drawdown' in name:\n",
    "        print(f\"  {name}: {value:.2%}\")\n",
    "    elif 'Ratio' in name:\n",
    "        print(f\"  {name}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {name}: {value}\")\n",
    "\n",
    "print(\"\\nМетрики прогнозов:\")\n",
    "print(f\"  RMSE: {baseline1_forecast_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE: {baseline1_forecast_metrics['mae']:.6f}\")\n",
    "print(f\"  Hit Rate: {baseline1_forecast_metrics['hit_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1495f4eb",
   "metadata": {},
   "source": [
    "## 5. Baseline 2: StatsForecast AutoARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b931022",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def build_long_frame(returns):\n",
    "    \"\"\"Преобразование в long-формат для StatsForecast.\"\"\"\n",
    "    df_long = returns.stack().reset_index()\n",
    "    df_long.columns = ['ds', 'unique_id', 'y']\n",
    "    return df_long\n",
    "\n",
    "\n",
    "def forecast_returns_statsforecast(train_returns, horizon, max_p, max_d, max_q, stepwise=True, return_raw=False):\n",
    "    \"\"\"Прогноз доходностей с помощью StatsForecast AutoARIMA.\"\"\"\n",
    "    df_long = build_long_frame(train_returns)\n",
    "    fallback = train_returns.mean()\n",
    "\n",
    "    model = AutoARIMA(\n",
    "        max_p=max_p,\n",
    "        max_q=max_q,\n",
    "        d=None,\n",
    "        max_d=max_d,\n",
    "        seasonal=False,\n",
    "        stepwise=stepwise\n",
    "    )\n",
    "    sf = StatsForecast(models=[model], freq='B', n_jobs=1)\n",
    "\n",
    "    try:\n",
    "        forecast_df = sf.forecast(h=horizon, df=df_long)\n",
    "    except Exception:\n",
    "        if return_raw:\n",
    "            # Возвращаем константу fallback для всех дней\n",
    "            raw = pd.DataFrame(\n",
    "                np.tile(fallback.values, (horizon, 1)),\n",
    "                columns=train_returns.columns\n",
    "            )\n",
    "            return fallback.values * 252, raw\n",
    "        return fallback.values * 252\n",
    "\n",
    "    col_name = 'AutoARIMA'\n",
    "    if col_name not in forecast_df.columns:\n",
    "        if return_raw:\n",
    "            raw = pd.DataFrame(\n",
    "                np.tile(fallback.values, (horizon, 1)),\n",
    "                columns=train_returns.columns\n",
    "            )\n",
    "            return fallback.values * 252, raw\n",
    "        return fallback.values * 252\n",
    "\n",
    "    # Годовая доходность\n",
    "    preds = forecast_df.groupby('unique_id')[col_name].mean()\n",
    "    preds = preds.reindex(train_returns.columns).fillna(fallback)\n",
    "    mu = preds.values * 252\n",
    "\n",
    "    if return_raw:\n",
    "        # Raw прогнозы: pivot для каждого дня\n",
    "        raw = forecast_df.pivot(index='ds', columns='unique_id', values=col_name)\n",
    "        raw = raw.reindex(columns=train_returns.columns).fillna(fallback)\n",
    "        return mu, raw\n",
    "\n",
    "    return mu\n",
    "\n",
    "\n",
    "def run_backtest_statsforecast(returns, train_window, test_window, rf, max_p, max_d, max_q, stepwise=True, collect_forecasts=True, collect_weights=False):\n",
    "    \"\"\"Бэктест: μ = прогноз StatsForecast AutoARIMA.\"\"\"\n",
    "    n = len(returns)\n",
    "    portfolio_returns = []\n",
    "    dates = []\n",
    "    forecast_records = [] if collect_forecasts else None\n",
    "    weights_list = [] if collect_weights else None\n",
    "\n",
    "    total_steps = (n - train_window - test_window) // test_window + 1\n",
    "    i = 0\n",
    "    step = 0\n",
    "\n",
    "    while i + train_window + test_window <= n:\n",
    "        train_data = returns.iloc[i:i + train_window]\n",
    "        test_data = returns.iloc[i + train_window:i + train_window + test_window]\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        # μ из ARIMA прогнозов\n",
    "        if collect_forecasts:\n",
    "            mu, raw_forecasts = forecast_returns_statsforecast(\n",
    "                train_data, test_window, max_p, max_d, max_q, stepwise, return_raw=True\n",
    "            )\n",
    "            # Actual = сумма дневных доходностей за месяц\n",
    "            actual_monthly = test_data.sum(axis=0)\n",
    "            # Predicted = сумма прогнозов за месяц\n",
    "            predicted_monthly = raw_forecasts.sum(axis=0)\n",
    "            # Собираем записи для каждого тикера\n",
    "            for ticker in returns.columns:\n",
    "                forecast_records.append({\n",
    "                    'date': test_data.index[0],\n",
    "                    'ticker': ticker,\n",
    "                    'actual': actual_monthly[ticker],\n",
    "                    'predicted': predicted_monthly[ticker],\n",
    "                    'model': 'StatsForecast'\n",
    "                })\n",
    "        else:\n",
    "            mu = forecast_returns_statsforecast(train_data, test_window, max_p, max_d, max_q, stepwise)\n",
    "\n",
    "        cov = compute_covariance(train_data, method=COV_METHOD, annualize=252)\n",
    "        weights = maximize_sharpe(\n",
    "            mu,\n",
    "            cov,\n",
    "            rf=rf,\n",
    "            min_weight=MIN_WEIGHT,\n",
    "            max_weight=MAX_WEIGHT,\n",
    "            long_only=LONG_ONLY,\n",
    "            fully_invested=FULLY_INVESTED,\n",
    "            gross_exposure=GROSS_EXPOSURE\n",
    "        )\n",
    "\n",
    "        month_return = compute_monthly_log_return(\n",
    "            test_data,\n",
    "            weights,\n",
    "            fully_invested=FULLY_INVESTED\n",
    "        )\n",
    "\n",
    "        portfolio_returns.append(month_return)\n",
    "        dates.append(test_data.index[0])\n",
    "        if weights_list is not None:\n",
    "            weights_list.append(weights)\n",
    "\n",
    "        if step % 10 == 0 or step == 1:\n",
    "            pct = step * 100 // total_steps\n",
    "            print(f\"  Шаг {step:3d}/{total_steps} ({pct:2d}%) | Дата: {test_data.index[0].date()}\")\n",
    "\n",
    "        i += test_window\n",
    "\n",
    "    print(f\"  Завершено: {step} периодов\")\n",
    "    result = pd.Series(portfolio_returns, index=dates)\n",
    "\n",
    "    # Возврат результатов\n",
    "    returns_tuple = [result]\n",
    "    if collect_forecasts:\n",
    "        forecasts_df = pd.DataFrame(forecast_records)\n",
    "        returns_tuple.append(forecasts_df)\n",
    "    if collect_weights:\n",
    "        weights_df = pd.DataFrame(weights_list, index=dates, columns=returns.columns)\n",
    "        returns_tuple.append(weights_df)\n",
    "\n",
    "    return tuple(returns_tuple) if len(returns_tuple) > 1 else result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d812d5b5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"Baseline 2: StatsForecast AutoARIMA\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Параметры: max_p={ARIMA_MAX_P}, max_d={ARIMA_MAX_D}, max_q={ARIMA_MAX_Q}, stepwise={ARIMA_STEPWISE}\")\n",
    "print(\"(stepwise=True ускоряет подбор ~10x)\\n\")\n",
    "\n",
    "baseline2_returns, baseline2_forecasts, baseline2_weights = run_backtest_statsforecast(\n",
    "    log_returns, TRAIN_WINDOW, TEST_WINDOW, RF, ARIMA_MAX_P, ARIMA_MAX_D, ARIMA_MAX_Q, ARIMA_STEPWISE,\n",
    "    collect_forecasts=True, collect_weights=True\n",
    ")\n",
    "baseline2_metrics = calculate_metrics(baseline2_returns, rf=RF)\n",
    "baseline2_forecast_metrics = aggregate_forecast_metrics(baseline2_forecasts)\n",
    "\n",
    "print(\"\\nРезультаты (Портфель):\")\n",
    "for name, value in baseline2_metrics.items():\n",
    "    if 'Return' in name or 'Volatility' in name or 'Drawdown' in name:\n",
    "        print(f\"  {name}: {value:.2%}\")\n",
    "    elif 'Ratio' in name:\n",
    "        print(f\"  {name}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {name}: {value}\")\n",
    "\n",
    "print(\"\\nМетрики прогнозов:\")\n",
    "print(f\"  RMSE: {baseline2_forecast_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE: {baseline2_forecast_metrics['mae']:.6f}\")\n",
    "print(f\"  Hit Rate: {baseline2_forecast_metrics['hit_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c6eb8f",
   "metadata": {},
   "source": [
    "## 6. PatchTST Self-Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b921f83",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PatchTST Official Architecture\n",
    "# (Based on https://github.com/yuqinie98/PatchTST)\n",
    "# Key features: Residual Attention, BatchNorm, Official heads\n",
    "# ============================================================\n",
    "\n",
    "class Transpose(nn.Module):\n",
    "    \"\"\"Transpose for BatchNorm.\"\"\"\n",
    "    def __init__(self, *dims, contiguous=False):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "        self.contiguous = contiguous\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.contiguous:\n",
    "            return x.transpose(*self.dims).contiguous()\n",
    "        return x.transpose(*self.dims)\n",
    "\n",
    "\n",
    "def get_activation_fn(activation):\n",
    "    if callable(activation):\n",
    "        return activation()\n",
    "    elif activation.lower() == \"relu\":\n",
    "        return nn.ReLU()\n",
    "    elif activation.lower() == \"gelu\":\n",
    "        return nn.GELU()\n",
    "    raise ValueError(f'{activation} is not available')\n",
    "\n",
    "\n",
    "def positional_encoding(pe, learn_pe, q_len, d_model):\n",
    "    \"\"\"Official positional encoding with uniform initialization.\"\"\"\n",
    "    if pe == 'zeros' or pe is None:\n",
    "        W_pos = torch.empty((q_len, d_model))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'sincos':\n",
    "        W_pos = torch.zeros(q_len, d_model)\n",
    "        position = torch.arange(0, q_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        W_pos[:, 0::2] = torch.sin(position * div_term)\n",
    "        W_pos[:, 1::2] = torch.cos(position * div_term)\n",
    "        W_pos = W_pos - W_pos.mean()\n",
    "        W_pos = W_pos / (W_pos.std() * 10)\n",
    "    else:\n",
    "        W_pos = torch.empty((q_len, d_model))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    return nn.Parameter(W_pos, requires_grad=learn_pe)\n",
    "\n",
    "\n",
    "class RevIN(nn.Module):\n",
    "    \"\"\"Reversible Instance Normalization.\"\"\"\n",
    "    def __init__(self, num_features, eps=1e-5, affine=True):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        if self.affine:\n",
    "            self.affine_weight = nn.Parameter(torch.ones(num_features))\n",
    "            self.affine_bias = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, x, mode):\n",
    "        if mode == 'norm':\n",
    "            self.mean = x.mean(dim=1, keepdim=True)\n",
    "            self.std = x.std(dim=1, keepdim=True) + self.eps\n",
    "            x = (x - self.mean) / self.std\n",
    "            if self.affine:\n",
    "                x = x * self.affine_weight + self.affine_bias\n",
    "        elif mode == 'denorm':\n",
    "            if self.affine:\n",
    "                x = (x - self.affine_bias) / self.affine_weight\n",
    "            x = x * self.std + self.mean\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention with Residual Attention support.\n",
    "    Residual Attention: scores are passed between layers for better\n",
    "    modeling of long sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads, d_k=None, d_v=None,\n",
    "                 attn_dropout=0., proj_dropout=0., res_attention=False):\n",
    "        super().__init__()\n",
    "        d_k = d_k or d_model // n_heads\n",
    "        d_v = d_v or d_model // n_heads\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.res_attention = res_attention\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        self.W_O = nn.Linear(d_v * n_heads, d_model, bias=False)\n",
    "\n",
    "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
    "        self.proj_dropout = nn.Dropout(proj_dropout)\n",
    "        self.scale = d_k ** -0.5\n",
    "\n",
    "    def forward(self, Q, K, V, prev=None):\n",
    "        bs, q_len, _ = Q.shape\n",
    "        _, k_len, _ = K.shape\n",
    "\n",
    "        Q = self.W_Q(Q).view(bs, q_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_K(K).view(bs, k_len, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_V(V).view(bs, k_len, self.n_heads, self.d_v).transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale\n",
    "\n",
    "        # Residual Attention: add previous scores\n",
    "        if prev is not None:\n",
    "            scores = scores + prev\n",
    "\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        attn = self.attn_dropout(attn)\n",
    "\n",
    "        context = torch.matmul(attn, V)\n",
    "        context = context.transpose(1, 2).contiguous().view(bs, q_len, -1)\n",
    "        output = self.W_O(context)\n",
    "        output = self.proj_dropout(output)\n",
    "\n",
    "        if self.res_attention:\n",
    "            return output, attn, scores\n",
    "        return output, attn\n",
    "\n",
    "\n",
    "class TSTEncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer Encoder Layer with official architecture:\n",
    "    - BatchNorm instead of LayerNorm (default)\n",
    "    - Residual Attention support\n",
    "    - Pre/Post norm option\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads, d_ff=256,\n",
    "                 norm='BatchNorm', attn_dropout=0., dropout=0.,\n",
    "                 activation='gelu', res_attention=False, pre_norm=False):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        d_k = d_model // n_heads\n",
    "        d_v = d_model // n_heads\n",
    "\n",
    "        self.res_attention = res_attention\n",
    "        self.pre_norm = pre_norm\n",
    "\n",
    "        self.self_attn = MultiheadAttention(\n",
    "            d_model, n_heads, d_k, d_v,\n",
    "            attn_dropout=attn_dropout, proj_dropout=dropout,\n",
    "            res_attention=res_attention\n",
    "        )\n",
    "\n",
    "        self.dropout_attn = nn.Dropout(dropout)\n",
    "\n",
    "        # Normalization after attention\n",
    "        if 'batch' in norm.lower():\n",
    "            self.norm_attn = nn.Sequential(\n",
    "                Transpose(1, 2), nn.BatchNorm1d(d_model), Transpose(1, 2)\n",
    "            )\n",
    "        else:\n",
    "            self.norm_attn = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Feed-Forward Network\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            get_activation_fn(activation),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "\n",
    "        self.dropout_ffn = nn.Dropout(dropout)\n",
    "\n",
    "        # Normalization after FFN\n",
    "        if 'batch' in norm.lower():\n",
    "            self.norm_ffn = nn.Sequential(\n",
    "                Transpose(1, 2), nn.BatchNorm1d(d_model), Transpose(1, 2)\n",
    "            )\n",
    "        else:\n",
    "            self.norm_ffn = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, src, prev=None):\n",
    "        if self.pre_norm:\n",
    "            src2 = self.norm_attn(src)\n",
    "        else:\n",
    "            src2 = src\n",
    "\n",
    "        if self.res_attention:\n",
    "            src2, attn, scores = self.self_attn(src2, src2, src2, prev)\n",
    "        else:\n",
    "            src2, attn = self.self_attn(src2, src2, src2)\n",
    "            scores = None\n",
    "\n",
    "        src = src + self.dropout_attn(src2)\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_attn(src)\n",
    "\n",
    "        if self.pre_norm:\n",
    "            src2 = self.ff(self.norm_ffn(src))\n",
    "        else:\n",
    "            src2 = self.ff(src)\n",
    "\n",
    "        src = src + self.dropout_ffn(src2)\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_ffn(src)\n",
    "\n",
    "        if self.res_attention:\n",
    "            return src, scores\n",
    "        return src\n",
    "\n",
    "\n",
    "class TSTEncoder(nn.Module):\n",
    "    \"\"\"Stack of TSTEncoderLayers.\"\"\"\n",
    "    def __init__(self, d_model, n_heads, d_ff=256,\n",
    "                 norm='BatchNorm', attn_dropout=0., dropout=0.,\n",
    "                 activation='gelu', res_attention=False, pre_norm=False,\n",
    "                 n_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TSTEncoderLayer(d_model, n_heads, d_ff, norm, attn_dropout, dropout,\n",
    "                           activation, res_attention, pre_norm)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.res_attention = res_attention\n",
    "\n",
    "    def forward(self, src):\n",
    "        output = src\n",
    "        scores = None\n",
    "        if self.res_attention:\n",
    "            for layer in self.layers:\n",
    "                output, scores = layer(output, prev=scores)\n",
    "        else:\n",
    "            for layer in self.layers:\n",
    "                output = layer(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class PretrainHead(nn.Module):\n",
    "    \"\"\"Head for self-supervised pretraining (official: dropout BEFORE linear).\"\"\"\n",
    "    def __init__(self, d_model, patch_len, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(d_model, patch_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(self.dropout(x))\n",
    "\n",
    "\n",
    "class PredictionHead(nn.Module):\n",
    "    \"\"\"Head for prediction (official: single linear layer).\"\"\"\n",
    "    def __init__(self, d_model, num_patches, pred_len, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(d_model * num_patches, pred_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class PatchTST_SelfSupervised(nn.Module):\n",
    "    \"\"\"\n",
    "    PatchTST with Official Architecture.\n",
    "    Key features:\n",
    "    - Residual Attention\n",
    "    - BatchNorm\n",
    "    - Official head structure\n",
    "    - Self-Supervised pretraining\n",
    "    \"\"\"\n",
    "    def __init__(self, input_len, pred_len, patch_len, stride,\n",
    "                 d_model, n_heads, n_layers, d_ff, dropout,\n",
    "                 mask_ratio, use_revin,\n",
    "                 # Official parameters\n",
    "                 norm='BatchNorm', res_attention=True, pre_norm=False,\n",
    "                 pe='zeros', learn_pe=True, attn_dropout=0.):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0, f\"d_model ({d_model}) must be divisible by n_heads ({n_heads})\"\n",
    "\n",
    "        self.input_len = input_len\n",
    "        self.pred_len = pred_len\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.use_revin = use_revin\n",
    "        self.d_model = d_model\n",
    "        self.num_patches = (input_len - patch_len) // stride + 1\n",
    "\n",
    "        # RevIN\n",
    "        if use_revin:\n",
    "            self.revin = RevIN(1, affine=True)\n",
    "\n",
    "        # Patch embedding\n",
    "        self.patch_embedding = nn.Linear(patch_len, d_model)\n",
    "\n",
    "        # Positional encoding (official)\n",
    "        self.W_pos = positional_encoding(pe, learn_pe, self.num_patches, d_model)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Transformer Encoder (official architecture)\n",
    "        self.encoder = TSTEncoder(\n",
    "            d_model=d_model, n_heads=n_heads, d_ff=d_ff,\n",
    "            norm=norm, attn_dropout=attn_dropout, dropout=dropout,\n",
    "            activation='gelu', res_attention=res_attention,\n",
    "            pre_norm=pre_norm, n_layers=n_layers\n",
    "        )\n",
    "\n",
    "        # Heads (official architecture)\n",
    "        self.pretrain_head = PretrainHead(d_model, patch_len, dropout)\n",
    "        self.prediction_head = PredictionHead(d_model, self.num_patches, pred_len, dropout)\n",
    "\n",
    "        # Mask token\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.mask_token, std=0.02)\n",
    "\n",
    "    def create_patches(self, x):\n",
    "        patches = []\n",
    "        for i in range(self.num_patches):\n",
    "            start = i * self.stride\n",
    "            patches.append(x[:, start:start + self.patch_len])\n",
    "        return torch.stack(patches, dim=1)\n",
    "\n",
    "    def random_masking(self, patches):\n",
    "        bs, num_patches, _ = patches.shape\n",
    "        num_mask = int(num_patches * self.mask_ratio)\n",
    "        noise = torch.rand(bs, num_patches, device=patches.device)\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)\n",
    "        ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "        mask = torch.zeros(bs, num_patches, device=patches.device)\n",
    "        mask[:, :num_mask] = 1\n",
    "        mask = torch.gather(mask, dim=1, index=ids_restore).bool()\n",
    "        return mask\n",
    "\n",
    "    def forward_encoder(self, x, mask=None):\n",
    "        bs = x.shape[0]\n",
    "\n",
    "        # RevIN normalization\n",
    "        if self.use_revin:\n",
    "            x = x.unsqueeze(-1)\n",
    "            x = self.revin(x, 'norm')\n",
    "            x = x.squeeze(-1)\n",
    "\n",
    "        # Create patches\n",
    "        patches = self.create_patches(x)\n",
    "\n",
    "        # Embedding\n",
    "        x = self.patch_embedding(patches)\n",
    "\n",
    "        # Apply mask\n",
    "        if mask is not None:\n",
    "            mask_tokens = self.mask_token.expand(bs, self.num_patches, -1)\n",
    "            x = torch.where(mask.unsqueeze(-1), mask_tokens, x)\n",
    "\n",
    "        # Positional encoding\n",
    "        x = self.dropout(x + self.W_pos)\n",
    "\n",
    "        # Transformer encoder\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        return x, patches\n",
    "\n",
    "    def forward_pretrain(self, x):\n",
    "        with torch.no_grad():\n",
    "            patches_for_mask = self.create_patches(x)\n",
    "            mask = self.random_masking(patches_for_mask)\n",
    "\n",
    "        encoded, original_patches = self.forward_encoder(x, mask)\n",
    "        pred_patches = self.pretrain_head(encoded)\n",
    "        loss = F.mse_loss(pred_patches[mask], original_patches[mask])\n",
    "        return loss, pred_patches, mask\n",
    "\n",
    "    def forward_predict(self, x):\n",
    "        encoded, _ = self.forward_encoder(x, mask=None)\n",
    "        prediction = self.prediction_head(encoded)\n",
    "\n",
    "        # RevIN denormalization\n",
    "        if self.use_revin and hasattr(self.revin, 'std'):\n",
    "            prediction = prediction * self.revin.std.squeeze(-1) + self.revin.mean.squeeze(-1)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def forward(self, x, mode='predict'):\n",
    "        if mode == 'pretrain':\n",
    "            return self.forward_pretrain(x)\n",
    "        return self.forward_predict(x)\n",
    "\n",
    "\n",
    "def pretrain_patchtst(model, data, epochs, lr, batch_size, verbose=False):\n",
    "    \"\"\"Self-Supervised pre-training.\"\"\"\n",
    "    model.train()\n",
    "    input_len = model.input_len\n",
    "\n",
    "    step = 5\n",
    "    X_train = []\n",
    "    for i in range(0, len(data) - input_len + 1, step):\n",
    "        X_train.append(data[i:i + input_len])\n",
    "    if len(X_train) == 0:\n",
    "        X_train = [data[-input_len:]]\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_tensor = torch.FloatTensor(X_train).to(device)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_tensor)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for (batch,) in loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss, _, _ = model(batch, mode='pretrain')\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "\n",
    "        if verbose and (epoch + 1) % 5 == 0:\n",
    "            print(f\"    Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(loader):.6f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def forecast_patchtst(model, last_input):\n",
    "    \"\"\"Прогноз.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.FloatTensor(last_input).unsqueeze(0).to(device)\n",
    "        pred = model(x, mode='predict')\n",
    "    return pred.cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "def create_sequences(data, input_len, pred_len):\n",
    "    \"\"\"Создание пар (вход, выход) для fine-tuning.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - input_len - pred_len + 1):\n",
    "        X.append(data[i:i + input_len])\n",
    "        y.append(data[i + input_len:i + input_len + pred_len])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def finetune_patchtst(model, X_train, y_train, epochs, lr, batch_size, verbose=False):\n",
    "    \"\"\"Fine-tuning prediction head.\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    X_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_tensor = torch.FloatTensor(y_train).to(device)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(X_batch, mode='predict')\n",
    "            loss = criterion(pred, y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        if verbose and (epoch + 1) % 5 == 0:\n",
    "            print(f\"    Finetune Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(loader):.6f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def forecast_returns_patchtst(train_returns, config, return_raw=False):\n",
    "    \"\"\"Прогноз доходностей с помощью PatchTST.\"\"\"\n",
    "    tickers = train_returns.columns\n",
    "    fallback = train_returns.mean()\n",
    "    horizon = config['pred_length']\n",
    "\n",
    "    # Собираем raw прогнозы для всех тикеров\n",
    "    raw_forecasts = pd.DataFrame(index=range(horizon), columns=tickers, dtype=float)\n",
    "\n",
    "    for ticker in tickers:\n",
    "        series = train_returns[ticker].values\n",
    "\n",
    "        if len(series) < config['input_length']:\n",
    "            # Мало данных — берём историческое среднее (константа на все дни)\n",
    "            raw_forecasts[ticker] = fallback[ticker]\n",
    "            continue\n",
    "\n",
    "        model = PatchTST_SelfSupervised(\n",
    "            input_len=config['input_length'],\n",
    "            pred_len=config['pred_length'],\n",
    "            patch_len=config['patch_length'],\n",
    "            stride=config['stride'],\n",
    "            d_model=config['d_model'],\n",
    "            n_heads=config['n_heads'],\n",
    "            n_layers=config['n_layers'],\n",
    "            d_ff=config['d_ff'],\n",
    "            dropout=config['dropout'],\n",
    "            mask_ratio=config['mask_ratio'],\n",
    "            use_revin=config['use_revin']\n",
    "        ).to(device)\n",
    "\n",
    "        model = pretrain_patchtst(\n",
    "            model, series,\n",
    "            epochs=config['pretrain_epochs'],\n",
    "            lr=config['pretrain_lr'],\n",
    "            batch_size=config['batch_size'],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Fine-tuning: обучаем prediction head (официальный подход)\n",
    "        X_train, y_train = create_sequences(series, config['input_length'], config['pred_length'])\n",
    "        if len(X_train) > 0:\n",
    "            model = finetune_patchtst(\n",
    "                model, X_train, y_train,\n",
    "                epochs=config['finetune_epochs'],\n",
    "                lr=config['pretrain_lr'] * 0.1,  # Меньший lr для fine-tuning\n",
    "                batch_size=config['batch_size'],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "        last_input = series[-config['input_length']:]\n",
    "        forecast = forecast_patchtst(model, last_input)\n",
    "\n",
    "        # Сохраняем raw прогноз (все horizon дней)\n",
    "        if len(forecast) == horizon:\n",
    "            raw_forecasts[ticker] = forecast\n",
    "        else:\n",
    "            # Fallback если прогноз другой длины\n",
    "            raw_forecasts[ticker] = fallback[ticker]\n",
    "\n",
    "    # mu = среднее по дням × 252\n",
    "    mu = raw_forecasts.mean(axis=0).values * 252\n",
    "\n",
    "    if return_raw:\n",
    "        return mu, raw_forecasts\n",
    "    return mu\n",
    "\n",
    "\n",
    "def run_backtest_patchtst(returns, train_window, test_window, rf, config, collect_forecasts=True, collect_weights=False):\n",
    "    \"\"\"Бэктест: μ = прогноз PatchTST.\"\"\"\n",
    "    n = len(returns)\n",
    "    portfolio_returns = []\n",
    "    dates = []\n",
    "    forecast_records = [] if collect_forecasts else None\n",
    "    weights_list = [] if collect_weights else None\n",
    "\n",
    "    total_steps = (n - train_window - test_window) // test_window + 1\n",
    "    i = 0\n",
    "    step = 0\n",
    "\n",
    "    while i + train_window + test_window <= n:\n",
    "        train_data = returns.iloc[i:i + train_window]\n",
    "        test_data = returns.iloc[i + train_window:i + train_window + test_window]\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        # μ из PatchTST прогнозов\n",
    "        if collect_forecasts:\n",
    "            mu, raw_forecasts = forecast_returns_patchtst(train_data, config, return_raw=True)\n",
    "            # Actual = сумма дневных доходностей за месяц\n",
    "            actual_monthly = test_data.sum(axis=0)\n",
    "            # Predicted = сумма прогнозов за месяц\n",
    "            predicted_monthly = raw_forecasts.sum(axis=0)\n",
    "            # Собираем записи для каждого тикера\n",
    "            for ticker in returns.columns:\n",
    "                forecast_records.append({\n",
    "                    'date': test_data.index[0],\n",
    "                    'ticker': ticker,\n",
    "                    'actual': actual_monthly[ticker],\n",
    "                    'predicted': predicted_monthly[ticker],\n",
    "                    'model': 'PatchTST'\n",
    "                })\n",
    "        else:\n",
    "            mu = forecast_returns_patchtst(train_data, config)\n",
    "\n",
    "        cov = compute_covariance(train_data, method=COV_METHOD, annualize=252)\n",
    "        weights = maximize_sharpe(\n",
    "            mu,\n",
    "            cov,\n",
    "            rf=rf,\n",
    "            min_weight=MIN_WEIGHT,\n",
    "            max_weight=MAX_WEIGHT,\n",
    "            long_only=LONG_ONLY,\n",
    "            fully_invested=FULLY_INVESTED,\n",
    "            gross_exposure=GROSS_EXPOSURE\n",
    "        )\n",
    "\n",
    "        month_return = compute_monthly_log_return(\n",
    "            test_data,\n",
    "            weights,\n",
    "            fully_invested=FULLY_INVESTED\n",
    "        )\n",
    "\n",
    "        portfolio_returns.append(month_return)\n",
    "        dates.append(test_data.index[0])\n",
    "        if weights_list is not None:\n",
    "            weights_list.append(weights)\n",
    "\n",
    "        if step % 5 == 0 or step == 1:\n",
    "            pct = step * 100 // total_steps\n",
    "            print(f\"  Шаг {step:3d}/{total_steps} ({pct:2d}%) | Дата: {test_data.index[0].date()}\")\n",
    "\n",
    "        i += test_window\n",
    "\n",
    "    print(f\"  Завершено: {step} периодов\")\n",
    "    result = pd.Series(portfolio_returns, index=dates)\n",
    "\n",
    "    # Возврат результатов\n",
    "    returns_tuple = [result]\n",
    "    if collect_forecasts:\n",
    "        forecasts_df = pd.DataFrame(forecast_records)\n",
    "        returns_tuple.append(forecasts_df)\n",
    "    if collect_weights:\n",
    "        weights_df = pd.DataFrame(weights_list, index=dates, columns=returns.columns)\n",
    "        returns_tuple.append(weights_df)\n",
    "\n",
    "    return tuple(returns_tuple) if len(returns_tuple) > 1 else result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6938feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(f\"PatchTST Self-Supervised (режим: {PATCHTST_MODE.upper()})\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Устройство: {device}\")\n",
    "print(f\"Патчей: {(INPUT_LEN - PATCH_LEN) // STRIDE + 1}\")\n",
    "print(f\"d_model={D_MODEL}, n_heads={N_HEADS}, n_layers={N_LAYERS}\")\n",
    "print(f\"pretrain_epochs={PRETRAIN_EPOCHS}, finetune_epochs={FINETUNE_EPOCHS}, lr={PRETRAIN_LR}\")\n",
    "print()\n",
    "\n",
    "patchtst_returns, patchtst_forecasts, patchtst_weights = run_backtest_patchtst(\n",
    "    log_returns, TRAIN_WINDOW, TEST_WINDOW, RF, patchtst_config,\n",
    "    collect_forecasts=True, collect_weights=True\n",
    ")\n",
    "patchtst_metrics = calculate_metrics(patchtst_returns, rf=RF)\n",
    "patchtst_forecast_metrics = aggregate_forecast_metrics(patchtst_forecasts)\n",
    "\n",
    "print(\"\\nРезультаты (Портфель):\")\n",
    "for name, value in patchtst_metrics.items():\n",
    "    if 'Return' in name or 'Volatility' in name or 'Drawdown' in name:\n",
    "        print(f\"  {name}: {value:.2%}\")\n",
    "    elif 'Ratio' in name:\n",
    "        print(f\"  {name}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {name}: {value}\")\n",
    "\n",
    "print(\"\\nМетрики прогнозов:\")\n",
    "print(f\"  RMSE: {patchtst_forecast_metrics['rmse']:.6f}\")\n",
    "print(f\"  MAE: {patchtst_forecast_metrics['mae']:.6f}\")\n",
    "print(f\"  Hit Rate: {patchtst_forecast_metrics['hit_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3822f77",
   "metadata": {},
   "source": [
    "## 7. Сравнение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b461f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Метрика': ['Годовая доходность', 'Годовая волатильность', 'Коэффициент Шарпа',\n",
    "                'Коэффициент Кальмара', 'Максимальная просадка', 'Общая доходность'],\n",
    "    'Baseline 1 (Ист. среднее)': [\n",
    "        f\"{baseline1_metrics['Annual Return']:.2%}\",\n",
    "        f\"{baseline1_metrics['Annual Volatility']:.2%}\",\n",
    "        f\"{baseline1_metrics['Sharpe Ratio']:.2f}\",\n",
    "        f\"{baseline1_metrics['Calmar Ratio']:.2f}\",\n",
    "        f\"{baseline1_metrics['Max Drawdown']:.2%}\",\n",
    "        f\"{baseline1_metrics['Total Return']:.2%}\"\n",
    "    ],\n",
    "    'Baseline 2 (StatsForecast)': [\n",
    "        f\"{baseline2_metrics['Annual Return']:.2%}\",\n",
    "        f\"{baseline2_metrics['Annual Volatility']:.2%}\",\n",
    "        f\"{baseline2_metrics['Sharpe Ratio']:.2f}\",\n",
    "        f\"{baseline2_metrics['Calmar Ratio']:.2f}\",\n",
    "        f\"{baseline2_metrics['Max Drawdown']:.2%}\",\n",
    "        f\"{baseline2_metrics['Total Return']:.2%}\"\n",
    "    ],\n",
    "    'PatchTST': [\n",
    "        f\"{patchtst_metrics['Annual Return']:.2%}\",\n",
    "        f\"{patchtst_metrics['Annual Volatility']:.2%}\",\n",
    "        f\"{patchtst_metrics['Sharpe Ratio']:.2f}\",\n",
    "        f\"{patchtst_metrics['Calmar Ratio']:.2f}\",\n",
    "        f\"{patchtst_metrics['Max Drawdown']:.2%}\",\n",
    "        f\"{patchtst_metrics['Total Return']:.2%}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"СРАВНЕНИЕ ВСЕХ ПОДХОДОВ\")\n",
    "print(\"=\"*60)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График\n",
    "cumulative1 = (1 + (np.exp(baseline1_returns) - 1)).cumprod()\n",
    "cumulative2 = (1 + (np.exp(baseline2_returns) - 1)).cumprod()\n",
    "cumulative3 = (1 + (np.exp(patchtst_returns) - 1)).cumprod()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(cumulative1.index, cumulative1.values, label='Baseline 1: Историческое среднее', linewidth=2)\n",
    "plt.plot(cumulative2.index, cumulative2.values, label='Baseline 2: StatsForecast', linewidth=2)\n",
    "plt.plot(cumulative3.index, cumulative3.values, label='PatchTST', linewidth=2, color='green')\n",
    "plt.title('Сравнение кумулятивных доходностей')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Рост капитала ($1 → $X)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Baseline 1: $1 → ${cumulative1.iloc[-1]:.2f}\")\n",
    "print(f\"Baseline 2: $1 → ${cumulative2.iloc[-1]:.2f}\")\n",
    "print(f\"PatchTST:   $1 → ${cumulative3.iloc[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccc1cf",
   "metadata": {},
   "source": [
    "## 8. Анализ ребалансировки портфелей\n",
    "\n",
    "В этом разделе анализируем, как модели меняют веса активов во времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Функция для расчёта turnover (оборота портфеля)\n",
    "def calculate_turnover(weights_df):\n",
    "    \"\"\"Turnover = среднее изменение весов между периодами.\"\"\"\n",
    "    diff = weights_df.diff().abs()\n",
    "    turnover = diff.sum(axis=1) / 2  # Делим на 2, т.к. продажа и покупка считаются дважды\n",
    "    return turnover\n",
    "\n",
    "# Рассчитываем turnover для всех моделей\n",
    "baseline1_turnover = calculate_turnover(baseline1_weights)\n",
    "baseline2_turnover = calculate_turnover(baseline2_weights)\n",
    "patchtst_turnover = calculate_turnover(patchtst_weights)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"АНАЛИЗ РЕБАЛАНСИРОВКИ ПОРТФЕЛЕЙ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBaseline 1 (Historical Mean):\")\n",
    "print(f\"  Средний turnover: {baseline1_turnover.mean():.2%}\")\n",
    "print(f\"  Максимум: {baseline1_turnover.max():.2%}\")\n",
    "\n",
    "print(f\"\\nBaseline 2 (StatsForecast):\")\n",
    "print(f\"  Средний turnover: {baseline2_turnover.mean():.2%}\")\n",
    "print(f\"  Максимум: {baseline2_turnover.max():.2%}\")\n",
    "\n",
    "print(f\"\\nPatchTST:\")\n",
    "print(f\"  Средний turnover: {patchtst_turnover.mean():.2%}\")\n",
    "print(f\"  Максимум: {patchtst_turnover.max():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmaps весов для каждой модели\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "\n",
    "# Baseline 1\n",
    "sns.heatmap(baseline1_weights.T, cmap='RdYlGn', center=0.1,\n",
    "            vmin=0, vmax=0.25, cbar_kws={'label': 'Вес в портфеле'},\n",
    "            ax=axes[0], xticklabels=20)\n",
    "axes[0].set_title('Baseline 1: Веса портфеля во времени', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Тикер')\n",
    "axes[0].set_xlabel('')\n",
    "\n",
    "# Baseline 2\n",
    "sns.heatmap(baseline2_weights.T, cmap='RdYlGn', center=0.1,\n",
    "            vmin=0, vmax=0.25, cbar_kws={'label': 'Вес в портфеле'},\n",
    "            ax=axes[1], xticklabels=20)\n",
    "axes[1].set_title('Baseline 2 (StatsForecast): Веса портфеля во времени', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Тикер')\n",
    "axes[1].set_xlabel('')\n",
    "\n",
    "# PatchTST\n",
    "sns.heatmap(patchtst_weights.T, cmap='RdYlGn', center=0.1,\n",
    "            vmin=0, vmax=0.25, cbar_kws={'label': 'Вес в портфеле'},\n",
    "            ax=axes[2], xticklabels=20)\n",
    "axes[2].set_title('PatchTST: Веса портфеля во времени', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Тикер')\n",
    "axes[2].set_xlabel('Период ребалансировки')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f45369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Траектории весов для PatchTST (наиболее активная модель)\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "for ticker in patchtst_weights.columns:\n",
    "    ax.plot(patchtst_weights.index, patchtst_weights[ticker],\n",
    "            label=ticker, linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax.set_title('PatchTST: Траектории весов активов во времени', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Дата')\n",
    "ax.set_ylabel('Вес в портфеле')\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 0.30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19efc908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение turnover по моделям\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "ax.plot(baseline1_turnover.index, baseline1_turnover.values,\n",
    "        label='Baseline 1', linewidth=2, alpha=0.7)\n",
    "ax.plot(baseline2_turnover.index, baseline2_turnover.values,\n",
    "        label='Baseline 2 (StatsForecast)', linewidth=2, alpha=0.7)\n",
    "ax.plot(patchtst_turnover.index, patchtst_turnover.values,\n",
    "        label='PatchTST', linewidth=2, alpha=0.7, color='green')\n",
    "\n",
    "ax.set_title('Сравнение оборота портфеля (Turnover)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Дата')\n",
    "ax.set_ylabel('Turnover (доля изменённых весов)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9bbfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Волатильность весов по активам\n",
    "weights_volatility = pd.DataFrame({\n",
    "    'Baseline 1': baseline1_weights.std(),\n",
    "    'Baseline 2': baseline2_weights.std(),\n",
    "    'PatchTST': patchtst_weights.std()\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "weights_volatility.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_title('Волатильность весов по активам', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Тикер')\n",
    "ax.set_ylabel('Стандартное отклонение веса')\n",
    "ax.legend(title='Модель')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nВолатильность весов по активам:\")\n",
    "print(weights_volatility.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение результатов\n",
    "baseline1_returns.to_csv('baseline1_returns.csv')\n",
    "baseline2_returns.to_csv('baseline2_returns.csv')\n",
    "patchtst_returns.to_csv('patchtst_returns.csv')\n",
    "comparison_df.to_csv('comparison_results.csv', index=False)\n",
    "\n",
    "print(\"Результаты сохранены\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
